version: '3.8'

services:
  # PostgreSQL for Hive Metastore
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: metastore
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - spark-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Hive Metastore
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: "-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore -Djavax.jdo.option.ConnectionUserName=postgres -Djavax.jdo.option.ConnectionPassword=postgres"
    ports:
      - "9083:9083"
    volumes:
      - ./conf/hive-site.xml:/opt/hive/conf/hive-site.xml
      - warehouse:/opt/hive/warehouse
    networks:
      - spark-network
    command: ["sh", "-c", "/opt/hive/bin/schematool -dbType postgres -initSchema || true && /opt/hive/bin/hive --service metastore"]

  # Spark Master
  spark-master:
    image: bitnami/spark:3.4
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
      - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./data:/data
      - warehouse:/warehouse
    networks:
      - spark-network

  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.4
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./data:/data
      - warehouse:/warehouse
    networks:
      - spark-network

  # Spark Application
  spark-app:
    build: .
    image: spark-billups:latest
    container_name: spark-app
    depends_on:
      - spark-master
      - spark-worker
      - hive-metastore
    volumes:
      - ./data:/data:ro
      - ./src:/app/src
      - ./reports:/app/reports
      - warehouse:/warehouse
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - HIVE_METASTORE_URI=thrift://hive-metastore:9083
      - PYSPARK_PYTHON=python3
      - SPARK_EXECUTOR_MEMORY=1g
      - SPARK_EXECUTOR_CORES=1
      - SPARK_DRIVER_MEMORY=1g
    networks:
      - spark-network
    command: ["python", "-m", "src.spark_job", "-t", "/data/historical_transactions.parquet", "-m", "/data/merchants.csv", "--task", "all", "-o", "/app/reports", "--no-hive"]

volumes:
  postgres_data:
  warehouse:

networks:
  spark-network:
    driver: bridge